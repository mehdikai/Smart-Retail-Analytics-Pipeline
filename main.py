"""
Script principal - Orchestration du pipeline Smart Retail Analytics
ExÃ©cute toutes les Ã©tapes : IntÃ©gration â†’ Normalisation â†’ FÃ©dÃ©ration â†’ Visualisation
"""

import os
import sys
import time
from datetime import datetime
import pandas as pd
from typing import Dict, Tuple

# Import des modules du projet
from integration import load_all_sources, load_config, display_data_info
from normalisation import normalize_all_sources
from federation import federate_all, display_federation_info
from visualisation import create_all_visualizations


def print_banner():
    """Affiche la banniÃ¨re du projet"""
    banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                            â•‘
    â•‘          SMART RETAIL ANALYTICS PIPELINE                   â•‘
    â•‘          Data Integration & Analysis System                â•‘
    â•‘                                                            â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)
    print(f"    ğŸ“… ExÃ©cution: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("    " + "="*60 + "\n")


def print_step(step_num: int, step_name: str):
    """Affiche le titre d'une Ã©tape"""
    print(f"\n{'='*60}")
    print(f"Ã‰TAPE {step_num} : {step_name.upper()}")
    print("="*60)


def save_processed_data(merged: pd.DataFrame, aggregations: Dict[str, pd.DataFrame], config: Dict):
    """
    Sauvegarde les donnÃ©es traitÃ©es
    
    Args:
        merged: DataFrame complet fusionnÃ©
        aggregations: Dictionnaire des agrÃ©gations
        config: Configuration
    """
    print("\nğŸ“ Sauvegarde des donnÃ©es traitÃ©es...")
    
    # CrÃ©er le dossier si nÃ©cessaire
    processed_path = config['output_paths']['processed_data']
    os.makedirs(processed_path, exist_ok=True)
    
    # Sauvegarder le dataset complet
    merged_file = os.path.join(processed_path, 'data_complete.csv')
    merged.to_csv(merged_file, index=False)
    print(f"   âœ“ Dataset complet: {merged_file}")
    
    # Sauvegarder les agrÃ©gations
    for name, df in aggregations.items():
        agg_file = os.path.join(processed_path, f'{name}.csv')
        df.to_csv(agg_file, index=False)
        print(f"   âœ“ AgrÃ©gation {name}: {agg_file}")
    
    print(f"\n   âœ… {len(aggregations) + 1} fichiers sauvegardÃ©s dans: {processed_path}")


def generate_summary_report(merged: pd.DataFrame, aggregations: Dict[str, pd.DataFrame], 
                           execution_time: float, config: Dict):
    """
    GÃ©nÃ¨re un rapport rÃ©sumÃ©
    
    Args:
        merged: DataFrame complet
        aggregations: Dictionnaire des agrÃ©gations
        execution_time: Temps d'exÃ©cution total
        config: Configuration
    """
    print("\nğŸ“ GÃ©nÃ©ration du rapport rÃ©sumÃ©...")
    
    # CrÃ©er le dossier si nÃ©cessaire
    report_path = config['output_paths']['report']
    os.makedirs(report_path, exist_ok=True)
    
    # CrÃ©er le rapport
    report_file = os.path.join(report_path, 'execution_summary.txt')
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("="*70 + "\n")
        f.write("SMART RETAIL ANALYTICS - RAPPORT D'EXÃ‰CUTION\n")
        f.write("="*70 + "\n\n")
        
        f.write(f"Date d'exÃ©cution: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Temps d'exÃ©cution: {execution_time:.2f} secondes\n\n")
        
        f.write("-"*70 + "\n")
        f.write("STATISTIQUES DES DONNÃ‰ES\n")
        f.write("-"*70 + "\n\n")
        
        # Dataset complet
        f.write(f"Dataset fusionnÃ©:\n")
        f.write(f"  â€¢ Lignes: {len(merged):,}\n")
        f.write(f"  â€¢ Colonnes: {len(merged.columns)}\n")
        f.write(f"  â€¢ PÃ©riode: {merged['date'].min()} Ã  {merged['date'].max()}\n\n")
        
        # AgrÃ©gations
        f.write("AgrÃ©gations crÃ©Ã©es:\n")
        for name, df in aggregations.items():
            f.write(f"  â€¢ {name}: {len(df):,} lignes\n")
        
        f.write("\n" + "-"*70 + "\n")
        f.write("INSIGHTS CLÃ‰S\n")
        f.write("-"*70 + "\n\n")
        
        # Top 5 campagnes
        f.write("Top 5 Campagnes Marketing:\n")
        top_campaigns = aggregations['campaign_sales'].head(5)
        for idx, row in top_campaigns.iterrows():
            f.write(f"  {idx+1}. {row['campaign_name']}: {row['total_amount']:,.2f}â‚¬ "
                   f"({row['order_count']} commandes)\n")
        
        f.write("\n")
        
        # Top 5 produits
        f.write("Top 5 Produits:\n")
        top_products = aggregations['product_sales'].head(5)
        for idx, row in top_products.iterrows():
            f.write(f"  {idx+1}. Produit #{row['product_id']}: {row['total_amount']:,.2f}â‚¬ "
                   f"({row['quantity']} unitÃ©s)\n")
        
        f.write("\n")
        
        # Top 5 pays
        f.write("Top 5 Pays:\n")
        top_countries = aggregations['country_sales'].head(5)
        for idx, row in top_countries.iterrows():
            f.write(f"  {idx+1}. {row['country']}: {row['total_amount']:,.2f}â‚¬ "
                   f"({row['order_count']} commandes)\n")
        
        f.write("\n" + "-"*70 + "\n")
        f.write("FICHIERS GÃ‰NÃ‰RÃ‰S\n")
        f.write("-"*70 + "\n\n")
        
        f.write("DonnÃ©es traitÃ©es:\n")
        f.write(f"  â€¢ {config['output_paths']['processed_data']}\n\n")
        
        f.write("Visualisations:\n")
        f.write(f"  â€¢ ventes_par_jour.png\n")
        f.write(f"  â€¢ ventes_par_campagne.png\n")
        f.write(f"  â€¢ trafic_vs_ventes.png\n")
        f.write(f"  Emplacement: {config['output_paths']['figures']}\n\n")
        
        f.write("="*70 + "\n")
        f.write("FIN DU RAPPORT\n")
        f.write("="*70 + "\n")
    
    print(f"   âœ“ Rapport sauvegardÃ©: {report_file}")


def main():
    """
    Fonction principale - ExÃ©cute le pipeline complet
    """
    start_time = time.time()
    
    try:
        # BanniÃ¨re
        print_banner()
        
        # Ã‰TAPE 1 : CHARGEMENT DE LA CONFIGURATION
        print_step(1, "Chargement de la configuration")
        config = load_config()
        print("âœ“ Configuration chargÃ©e avec succÃ¨s")
        
        # Ã‰TAPE 2 : INTÃ‰GRATION DES SOURCES
        print_step(2, "IntÃ©gration des sources de donnÃ©es")
        raw_data = load_all_sources(config)
        print("\nâœ“ Toutes les sources chargÃ©es avec succÃ¨s")
        
        # Ã‰TAPE 3 : NORMALISATION
        print_step(3, "Normalisation des donnÃ©es")
        normalized_data = normalize_all_sources(raw_data)
        print("\nâœ“ Normalisation terminÃ©e avec succÃ¨s")
        
        # Ã‰TAPE 4 : FÃ‰DÃ‰RATION
        print_step(4, "FÃ©dÃ©ration des donnÃ©es")
        merged, aggregations = federate_all(normalized_data)
        print("\nâœ“ FÃ©dÃ©ration terminÃ©e avec succÃ¨s")
        
        # Ã‰TAPE 5 : VISUALISATION
        print_step(5, "CrÃ©ation des visualisations")
        filepaths = create_all_visualizations(aggregations, config)
        print("\nâœ“ Visualisations crÃ©Ã©es avec succÃ¨s")
        
        # Ã‰TAPE 6 : SAUVEGARDE
        print_step(6, "Sauvegarde des rÃ©sultats")
        save_processed_data(merged, aggregations, config)
        
        # Ã‰TAPE 7 : RAPPORT
        execution_time = time.time() - start_time
        generate_summary_report(merged, aggregations, execution_time, config)
        
        # RÃ‰SUMÃ‰ FINAL
        print("\n" + "="*60)
        print("EXÃ‰CUTION TERMINÃ‰E AVEC SUCCÃˆS")
        print("="*60)
        print(f"\nâ±ï¸  Temps total: {execution_time:.2f} secondes")
        print(f"ğŸ“Š Dataset: {len(merged):,} lignes, {len(merged.columns)} colonnes")
        print(f"ğŸ“ˆ Graphiques: {len(filepaths)} crÃ©Ã©s")
        print(f"ğŸ“ AgrÃ©gations: {len(aggregations)} sauvegardÃ©es")
        print(f"\nâœ… Pipeline exÃ©cutÃ© avec succÃ¨s!")
        print(f"\nğŸ“‚ Consultez les rÃ©sultats dans:")
        print(f"   â€¢ DonnÃ©es: {config['output_paths']['processed_data']}")
        print(f"   â€¢ Figures: {config['output_paths']['figures']}")
        print(f"   â€¢ Rapport: {config['output_paths']['report']}")
        print("\n" + "="*60 + "\n")
        
        return 0  # SuccÃ¨s
        
    except Exception as e:
        print(f"\nâŒ ERREUR LORS DE L'EXÃ‰CUTION DU PIPELINE")
        print(f"âŒ {str(e)}")
        import traceback
        traceback.print_exc()
        return 1  # Ã‰chec


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)